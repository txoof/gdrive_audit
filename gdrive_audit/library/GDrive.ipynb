{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd64a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7358ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from . import constants_GDrive\n",
    "except ImportError:\n",
    "    import constants_GDrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bda6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from json import JSONDecodeError\n",
    "import logging\n",
    "from os import path\n",
    "from functools import wraps\n",
    "from ssl import SSLError\n",
    "import time\n",
    "\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.auth import exceptions as google_exceptions\n",
    "from ratelimit import limits, sleep_and_retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb64cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b47a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDriveError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap any call to the service in this decorator \n",
    "# see: https://stackoverflow.com/a/36944992/5530152\n",
    "def credential_wrapper(method):\n",
    "    '''decorator refreshes/creates credentials as needed\n",
    "    \n",
    "    updates self.credentials and writes token file as needed.\n",
    "    \n",
    "    Args:\n",
    "        method(class function)\n",
    "        \n",
    "    Returns:\n",
    "        method(class function)'''\n",
    "    @wraps(method)\n",
    "    def _impl(self, *method_args, **method_kwargs):\n",
    "        if not self.credentials or not self.credentials.valid:\n",
    "            if self.credentials and self.credentials.expired and self.credentials.refresh_token:\n",
    "                self.credentials.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.secrets, self.scopes)\n",
    "                self.credentials = flow.run_local_server(port=0)\n",
    "                \n",
    "                # save the credentials for the next run\n",
    "                try:\n",
    "                    with open(self.token, 'w') as token_file:\n",
    "                        token_file.write(self.credentials.to_json())\n",
    "                except OSError as e:\n",
    "                    raise GDriveError(f'error writing token file: {self.token} - {e}')\n",
    "            # finally build/update service using credentials\n",
    "            self.build_service(self.credentials)\n",
    "        method_output = method(self, *method_args, **method_kwargs)\n",
    "        return method_output\n",
    "    return _impl                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retryer(max_retries=10, timeout=2):\n",
    "    '''\n",
    "    Retry on specific network related errors with timeout\n",
    "    https://pragmaticcoders.com/blog/retrying-exceptions-handling-internet-connection-problems/\n",
    "    '''\n",
    "    logger.debug(f'max_retries: {max_retries}, timeout: {timeout}')\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def retry(*args, **kwargs):\n",
    "            \n",
    "            network_exceptions = (HttpError, SSLError, BrokenPipeError)\n",
    "            exceptions = []\n",
    "            \n",
    "            for i in range(max_retries):\n",
    "                logger.debug(f'attempt: {i}')\n",
    "                try:\n",
    "                    result = func(*args, **kwargs)\n",
    "                except network_exceptions as e:\n",
    "                    logger.debug(f'attempt failed with error: {e}')\n",
    "                    time.sleep(timeout)\n",
    "                    exceptions.append(e)\n",
    "                    continue\n",
    "                else:\n",
    "                    return result\n",
    "            else:\n",
    "                raise GDriveError(f'could not complete connection due to multiple errors: {exceptions}')\n",
    "        return retry\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63841c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDrive():\n",
    "    def __repr__(self):\n",
    "        return 'GDrive()'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'GDrive()'\n",
    "    \n",
    "    def __init__(self, secrets, scopes, cache='./', token='token.json'):\n",
    "        '''create a google drive interface for searching and returning file/folder information\n",
    "        \n",
    "        Args:\n",
    "            secrets(Path): secrets json file obtained from https://console.cloud.google.com/cloud-resource-manager\n",
    "            token(Path): file to cache auth information (typically within cache path)\n",
    "        '''\n",
    "        self.secrets = secrets\n",
    "        self.scopes = scopes        \n",
    "        self.token = Path(cache)/token\n",
    "        logging.debug(f'Token: {self.token}')\n",
    "        self.credentials = self.set_credentials(secrets=self.secrets, \n",
    "                                            scopes=self.scopes, \n",
    "                                            token=self.token)\n",
    "        self.service = self.build_service(self.credentials)\n",
    "        self.MIMETYPES = constants_GDrive.MIMETYPES\n",
    "        self.CORPORA = constants_GDrive.CORPORA\n",
    "        self.FILE_FIELDS = constants_GDrive.FILE_FIELDS\n",
    "        self.FIELDS_DEFAULT = constants_GDrive.FIELDS_DEFAULT\n",
    "        self.PAGESIZE = constants_GDrive.PAGESIZE\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    # may be possible to replace this with the credential_wapper decorator \n",
    "    def set_credentials(secrets, token, scopes, force=False):\n",
    "        token = Path(token).expanduser()\n",
    "        secrets = Path(secrets).expanduser()\n",
    "        creds = None\n",
    "        logging.debug(f'Token: {token}; Secrets: {secrets}')\n",
    "\n",
    "        if token.exists():\n",
    "            creds = Credentials.from_authorized_user_file(token, scopes)\n",
    "\n",
    "\n",
    "        if not creds or not creds.valid or force:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())    \n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(secrets, scopes)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            # Save the credentials for the next run\n",
    "            try:\n",
    "                with open(token, 'w') as token:\n",
    "                    token.write(creds.to_json())\n",
    "            except OSError as e:\n",
    "                raise GDRiveError(f'error writing token file: {token} - {e}')\n",
    "\n",
    "        return creds    \n",
    "# \n",
    "    \n",
    "    @staticmethod\n",
    "    def build_service(credentials):\n",
    "        try:\n",
    "            service  = build('drive', 'v3', credentials=credentials)\n",
    "        except google_exceptions.GoogleAuthError as e:\n",
    "            raise GDriveError(f'error building credentials: {e}')\n",
    "        return service\n",
    "    \n",
    "                \n",
    "    @property\n",
    "    def token(self):\n",
    "        '''token file'''\n",
    "        return self._token\n",
    "        \n",
    "    @token.setter\n",
    "    def token(self, t_path):\n",
    "        t_path = Path(t_path)        \n",
    "        self._token = t_path\n",
    "            \n",
    "\n",
    "    def _check_fields(self, fields, forcefields=False):\n",
    "        '''check that files are valid\n",
    "        \n",
    "        Args:\n",
    "            fields(list): list of fields\n",
    "            forcefields(bool): When true, ignore unknown fields\n",
    "            \n",
    "        Returns:\n",
    "            list'''\n",
    "        known_fields = []\n",
    "        fields = set(fields)\n",
    "        for f in fields:\n",
    "            if f not in self.FILE_FIELDS:\n",
    "                if forcefields:\n",
    "                    logger.warning(f'unknown return field: {f}')\n",
    "                    known_fields.append(f)\n",
    "                else:\n",
    "                    raise GDriveError(f'unknown return field: {f}')\n",
    "            else:\n",
    "                known_fields.append(f)\n",
    "    \n",
    "        return known_fields\n",
    "\n",
    "    def _get_interface(self, fileId, fields=[], forcefields=False):\n",
    "        \n",
    "        known_fields = self._check_fields(fields, forcefields)\n",
    "        \n",
    "        return {'fileId': fileId,\n",
    "                'fields': ','.join(known_fields),\n",
    "               }\n",
    "    \n",
    "    \n",
    "    def _list_interface(self, name=None, trashed=False, mimeType=None, fuzzy=True, \n",
    "               modifiedTime=None, parents=None, dopperator='>',\n",
    "               fields = [], forcefields=False,\n",
    "               corpora='user', orderBy='createdTime', driveId='',):\n",
    "        '''priavate method to create dict for interfacing with files API\n",
    "        \n",
    "        Args:\n",
    "            name(str): string to search for\n",
    "            trashed(bool): false: do not search in trashed items\n",
    "            mimeType(str): search for known mimeType (see self.MIMETYPES)\n",
    "            fuzzy(bool): true: use `like` opperator when searching for names; \n",
    "                false: use `=` opperator when searching for names\n",
    "            modifiedTime(str): YYYY-MM-DD formatted date for checking modified times\n",
    "            parents(str): folder ID string used for searching within folders\n",
    "            dopperator(str): >, <, =, >=, <= search for items with modified time\n",
    "            fields(list of str): fields to return in search (see self.FIELDS)\n",
    "            forcefields(bool): False: reject fields not found in self.FIELDS\n",
    "            corpora(str): locations within drive to search (see self.CORPORA)\n",
    "            orderBy(str): order results by\n",
    "            driveId(str): drive identifier string; use for searching within a\n",
    "                specific shared drive\n",
    "        \n",
    "        Returns:\n",
    "            dict: {'q': 'constructed query string',\n",
    "                'corpora': 'corpora identifier',\n",
    "                'includeItemsFromAllDrives': 'True/False',\n",
    "                'supportsAllDrives': 'True/False',\n",
    "                'fields_string': 'nextPageToken, files(field1,field2,fieldN)',\n",
    "                'driveId': 'drive identifier string',\n",
    "                }\n",
    "            '''\n",
    "        \n",
    "        query_build = {\n",
    "            'name': (name, f'name {\"contains\" if fuzzy else \"=\"} \"{name}\"'),\n",
    "            'trashed': (trashed, f'trashed={trashed}'),\n",
    "            'mimeType': (mimeType, f'mimeType=\"{self.MIMETYPES[mimeType] if mimeType in self.MIMETYPES else \"\"}\"'),\n",
    "            'parents': (parents, f'\"{parents}\" in parents'),\n",
    "            'modifiedTime': (modifiedTime, f'modifiedTime{dopperator}\"{modifiedTime}\"')\n",
    "        }\n",
    "        \n",
    "        query = [v[1] for k, v in query_build.items() if v[0]]\n",
    "        \n",
    "        if len(fields) < 1:\n",
    "            fields = self.FIELDS_DEFAULT\n",
    "        fields = set(fields)\n",
    "#         known_fields = []\n",
    "#         for f in fields:\n",
    "#             if f not in self.FILE_FIELDS:\n",
    "#                 if forcefields:\n",
    "#                     logger.warning(f'unknown return field: {f}')\n",
    "#                     known_fields.append(f)\n",
    "#                 else:\n",
    "#                     raise GDriveError(f'unknown return field: {f}')\n",
    "#             else:\n",
    "#                 known_fields.append(f)\n",
    "\n",
    "        known_fields = self._check_fields(fields, forcefields)\n",
    "    \n",
    "        fields_string = f'nextPageToken, files({\",\".join(known_fields)})'\n",
    "        \n",
    "        if driveId:\n",
    "            corpora = 'drive'\n",
    "        if corpora not in self.CORPORA:\n",
    "            raise GDriveError(f'unknown `corpora` value: {corpora}')\n",
    "        else:\n",
    "            includeItemsFromAllDrives = self.CORPORA[corpora]['params']['includeItemsFromAllDrives']\n",
    "            supportsAllDrives = self.CORPORA[corpora]['params']['supportsAllDrives']\n",
    "            \n",
    "        q = ' and '.join(query)\n",
    "        logger.debug(f'QUERY STRING: {q}')\n",
    "        \n",
    "        return {'q': q,\n",
    "                'corpora': corpora,\n",
    "                'includeItemsFromAllDrives': includeItemsFromAllDrives,\n",
    "                'supportsAllDrives': supportsAllDrives,\n",
    "                'fields_string': fields_string,\n",
    "                'driveId': driveId,\n",
    "                }\n",
    "    \n",
    "    @credential_wrapper\n",
    "    @sleep_and_retry\n",
    "    @limits(calls=constants_GDrive.CALL_LIMIT, period=constants_GDrive.CALL_PERIOD)\n",
    "    def _list(self, q='', corpora='', includeItemsFromAllDrives=False,\n",
    "             supportsAllDrives='', fields_string='', driveId='', \n",
    "              pageToken='', pageSize=constants_GDrive.PAGESIZE):\n",
    "        '''private function for listing within a drive'''\n",
    "        logger.debug(f'fettching page of {pageSize} results with query {q}')\n",
    "        try:\n",
    "            results = self.service.files().list(q=q,\n",
    "                                                corpora=corpora,\n",
    "                                                includeItemsFromAllDrives=includeItemsFromAllDrives,\n",
    "                                                supportsAllDrives=supportsAllDrives,\n",
    "                                                fields=fields_string,\n",
    "                                                driveId=driveId,\n",
    "                                                pageSize=pageSize,\n",
    "                                                pageToken=pageToken\n",
    "                                                ).execute()\n",
    "        except HttpError as e:\n",
    "            raise GDriveError(f'error searching: {type(e)}: {e}')\n",
    "\n",
    "        return results\n",
    "\n",
    "#     @credential_wrapper\n",
    "#     @sleep_and_retry\n",
    "#     @limits(calls=constants_GDrive.CALL_LIMIT, period=constants_GDrive.CALL_PERIOD)\n",
    "#     def _get(self, fileId, fields=None, supportsAllDrives=''):\n",
    "#         '''private function for making get call on item'''\n",
    "#         logger.debug(f'fetching details: {fields_string} for item: {fileId}')\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if not fields or len(fields) < 1:\n",
    "#             fields_string = ','.join(self.FIELDS_DEFAULT)\n",
    "#         try:\n",
    "#             results = self.service.files().get(fileId=fileId, fields=fields_string,\n",
    "#                                              supportsAllDrives=supportsAllDrives).execute()\n",
    "#         except HttpError as e:\n",
    "#             raise GDriveError(f'error getting file details: {type(e)}: {e}')\n",
    "        \n",
    "#         return results\n",
    "\n",
    "    @retryer(max_retries=5)\n",
    "    @credential_wrapper\n",
    "    @sleep_and_retry\n",
    "    @limits(calls=constants_GDrive.CALL_LIMIT, period=constants_GDrive.CALL_PERIOD)\n",
    "    def get_properties(self, fileId, fields=constants_GDrive.FIELDS_DEFAULT, supportsAllDrives=True):\n",
    "        interface = self._get_interface(fileId, fields)\n",
    "        try:\n",
    "            results = self.service.files().get(**interface, supportsAllDrives=True).execute()\n",
    "        except HttpError as e:\n",
    "            raise GDriveError(f'error getting file details: {type(e)}: {e}')\n",
    "        \n",
    "        return results        \n",
    "    \n",
    "    @retryer(max_retries=5)    \n",
    "    def search(self, name=None, trashed=False, mimeType=None, fuzzy=True, \n",
    "               modifiedTime=None, parents=None, dopperator='>',\n",
    "               fields = [], forcefields=False,\n",
    "               corpora='user', orderBy='createdTime', driveId='',\n",
    "               pageSize=constants_GDrive.PAGESIZE, complete=True,\n",
    "               pageToken=''):\n",
    "        '''search for objects in google drive by name\n",
    "\n",
    "        Args:\n",
    "            name(str): string to search for\n",
    "            trashed(bool): search in trash when true\n",
    "            mimeType(str): short mimeType (see MIMETYPES property)\n",
    "            fuzzy(bool): true: `name contains \"value\"` false: `name = \"value\"`\n",
    "            modifiedTime(str): yyyy-mm-dd string\n",
    "            dopperator(str): >, < for use with modifiedTime\n",
    "            parents(str): folder to search within\n",
    "            fields(list of str): fields to return (see FILE_FIELDS property)\n",
    "            forcefields(bool): true: use unknown fields, false: reject fields not in FILE_FIELDS\n",
    "            corpora(str): locations to search (see CORPORA property)\n",
    "            orderBy(str): order results by (see https://developers.google.com/drive/api/v3/reference/files/list)\n",
    "            driveId(str): search this shared drive\n",
    "            pageSize(int): number of results to return per page (default 300)\n",
    "            complete(bool): true: exhaust all nextPageTokens\n",
    "\n",
    "        Retruns dict of resutls'''\n",
    "\n",
    "        interface = self._list_interface(name=name, trashed=trashed, mimeType=mimeType, fuzzy=fuzzy, \n",
    "               modifiedTime=modifiedTime, parents=parents, dopperator=dopperator,\n",
    "               fields = fields, forcefields=forcefields,\n",
    "               corpora=corpora, orderBy=orderBy, driveId=driveId)\n",
    "        \n",
    "        file_list = []\n",
    "        search_result = self._list(pageToken=pageToken, **interface)\n",
    "                    \n",
    "        token = search_result.get('nextPageToken', False)\n",
    "        file_list.extend(search_result.get('files', []))\n",
    "        \n",
    "        while token and complete:\n",
    "            logger.debug(f'processing additional pages of results')\n",
    "            search_result = self._list(pageToken=token, **interface) # need to pass pagetoken=token and **interface\n",
    "            token = search_result.get('nextPageToken', False)\n",
    "            file_list.extend(search_result.get('files', []))\n",
    "\n",
    "\n",
    "        logger.debug(f'{len(file_list)} total matches returned')\n",
    "        \n",
    "        return file_list\n",
    "\n",
    "    @retryer(max_retries=5)\n",
    "    def ls(self, *args, **kwargs):\n",
    "        '''print lis of files in a google drive using any of the search properties'''\n",
    "\n",
    "        result = self.search(*args, **kwargs)\n",
    "        for file in result.get('files', []):\n",
    "            print(('name: {f[name]}, ID:{f[id]}, mimeType:{f[mimeType]}'.format(f=file)))\n",
    "\n",
    "        return result\n",
    "    \n",
    "    @retryer(max_retries=5)\n",
    "    @credential_wrapper\n",
    "    def add_file(self, file, name=None, target_mimeType=None, parents=None, fields=['id', 'webViewLink', 'mimeType']):\n",
    "        '''add a local file to google drive\n",
    "\n",
    "        Args:\n",
    "            file(str): path to local file to upload\n",
    "            name(str): name of file\n",
    "            target_mimeType(str): save as this mime type on google drive (see self.MIMETYPES and note below)\n",
    "            parents(str): folder id\n",
    "            fields(list of str): file properties to return see self.FILE_FIELDS\n",
    "\n",
    "        mimeTypes -- https://developers.google.com/drive/api/v3/reference/files/create\n",
    "        Google Drive will attempt to automatically detect an\n",
    "        appropriate value from uploaded content if no value is\n",
    "        provided. The value cannot be changed unless a new revision\n",
    "        is uploaded.\n",
    "\n",
    "        If a file is created with a Google Doc MIME type, the\n",
    "        uploaded content will be imported if possible. The\n",
    "        supported import formats are published in the About\n",
    "        resource.\n",
    "\n",
    "        Returns:\n",
    "            dict of str containing requestesd fields\n",
    "            '''\n",
    "\n",
    "\n",
    "        file = Path(file).expanduser().resolve()\n",
    "        if not name:\n",
    "            name = file.name\n",
    "\n",
    "        target_mimeType = self.MIMETYPES.get(target_mimeType, target_mimeType)\n",
    "\n",
    "        if not target_mimeType:\n",
    "            logger.warning('no mime type set: google will attempt to guess type based on content')\n",
    "\n",
    "        file_metadata = {'name': name,\n",
    "                         'mimeType': f'{target_mimeType if target_mimeType else \"\"}'}\n",
    "\n",
    "        media = MediaFileUpload(filename=file)\n",
    "\n",
    "        upload = self.service.files().create(body=file_metadata,\n",
    "                                             media_body=media,\n",
    "                                             fields=','.join(fields)).execute()\n",
    "\n",
    "        return upload\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = GDrive(secrets='/Users/aciuffo/.cache/gdrive_audit/client_secrets.json', scopes=['https://www.googleapis.com/auth/drive'], cache='~/.cache/gdrive_audit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import constants\n",
    "\n",
    "# sec = '/Users/aciuffo/.cache/gdrive_audit/client_secrets.json'\n",
    "# d = GDrive(secrets=sec, scopes=constants.SCOPES)\n",
    "\n",
    "# f = d.add_file(file='./foo.txt', name='always take the weather with you...', target_mimeType='docs')\n",
    "\n",
    "# r = d.search(parents='0B9WTleJ1MzaYT2pieWNXYkZtZm8', fields=['parents', 'id', 'name', 'mimeType'], pageSize=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# logger.debug('foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DC():\n",
    "    '''dummy class for developing class functions'''\n",
    "    pass\n",
    "self = DC()\n",
    "# self.mimetypes = constants_GDrive.MIMETYPES\n",
    "# self.service = d.service\n",
    "# self.MIMETYPES = d.MIMETYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6278c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook GDrive.ipynb to python\n",
      "[NbConvertApp] Writing 18801 bytes to GDrive.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter-nbconvert --to python --template python_clean GDrive.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdrive_audit-k7Dny7ri",
   "language": "python",
   "name": "gdrive_audit-k7dny7ri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
