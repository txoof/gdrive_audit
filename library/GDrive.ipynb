{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd64a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7358ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from . import constants_GDrive\n",
    "except ImportError:\n",
    "    import constants_GDrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22bda6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from json import JSONDecodeError\n",
    "import logging\n",
    "# from time import time\n",
    "from os import path\n",
    "# import json\n",
    "# from datetime import datetime, timezone\n",
    "# from dateutil import parser\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.auth import exceptions as google_exceptions\n",
    "from ratelimit import limits, sleep_and_retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb64cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b47a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDriveError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c38856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wrap any call to the service in this decorator \n",
    "# # see: https://stackoverflow.com/a/36944992/5530152\n",
    "# def credential_wrapper(method):\n",
    "#     @wraps(method)\n",
    "#     def _impl(self, *method_args, **method_kwargs):\n",
    "#         # look at the example from google and rewrite this mess\n",
    "#         if self.credentials.expired and self.credentials.refresh_token:\n",
    "#             self.credentials.refresh(Request())\n",
    "#         else:\n",
    "#             flow = InstalledAppFlow.from_client_secrets_file(self.secrets, self.scopes)\n",
    "#             creds = flow.run_local_server(port=0)\n",
    "#             self.credentials = creds\n",
    "#         # Save the credentials for the next run\n",
    "#             try:\n",
    "#                 with open('token.json', 'w') as token:\n",
    "#                     token.write(creds.to_json())\n",
    "#             except OSError as e:\n",
    "#                 raise GDRiveError(f'error writing token file: {token} - {e}')\n",
    "            \n",
    "            \n",
    "#         method_output = method(self, *method_args, **method_kwargs)\n",
    "#         return method_output\n",
    "#     return _impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bec289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap any call to the service in this decorator \n",
    "# see: https://stackoverflow.com/a/36944992/5530152\n",
    "def credential_wrapper(method):\n",
    "    @wraps(method)\n",
    "    def _impl(self, *method_args, **method_kwargs):\n",
    "        if not self.credentials or not self.credentials.valid:\n",
    "            if self.credentials and self.credentials.expired and self.credentials.refresh_token:\n",
    "                self.credentials.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.secrets, self.scopes)\n",
    "                self.credentials = flow.run_local_server(port=0)\n",
    "                \n",
    "                # save the credentials for the next run\n",
    "                try:\n",
    "                    with open(self.token, 'w') as token_file:\n",
    "                        token_file.write(self.credentials.to_json())\n",
    "                except OSError as e:\n",
    "                    raise GDriveError(f'error writing token file: {self.token} - {e}')\n",
    "            self.build_service(self.credentials)\n",
    "        method_output = method(self, *method_args, **method_kwargs)\n",
    "        return method_output\n",
    "    return _impl                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63841c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDrive():\n",
    "    def __repr__(self):\n",
    "        return 'GDrive()'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'GDrive()'\n",
    "    \n",
    "    def __init__(self, secrets, scopes, cache='./', token='./token.json'):\n",
    "        '''create a google drive interface for searching and returning file/folder information\n",
    "        \n",
    "        Args:\n",
    "            secrets(Path): secrets json file obtained from https://console.cloud.google.com/cloud-resource-manager\n",
    "            token(Path): file to cache auth information (typically within cache path)\n",
    "        '''\n",
    "        self.secrets = secrets\n",
    "        self.scopes = scopes        \n",
    "        self.token = token\n",
    "        self.credentials = self.set_credentials(secrets=self.secrets, \n",
    "                                            scopes=self.scopes, \n",
    "                                            token=self.token)\n",
    "        self.service = self.build_service(self.credentials)\n",
    "        self.MIMETYPES = constants_GDrive.MIMETYPES\n",
    "        self.CORPORA = constants_GDrive.CORPORA\n",
    "        self.FILE_FIELDS = constants_GDrive.FILE_FIELDS\n",
    "        self.FIELDS_DEFAULT = constants_GDrive.FIELDS_DEFAULT\n",
    "        self.PAGESIZE = constants_GDrive.PAGESIZE\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def set_credentials(secrets, token, scopes, force=False):\n",
    "        token = Path(token).expanduser()\n",
    "        secrets = Path(secrets).expanduser()\n",
    "        creds = None\n",
    "\n",
    "        if token.exists():\n",
    "            creds = Credentials.from_authorized_user_file(token, scopes)\n",
    "\n",
    "\n",
    "        if not creds or not creds.valid or force:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())    \n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(secrets, scopes)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            # Save the credentials for the next run\n",
    "            try:\n",
    "                with open('token.json', 'w') as token:\n",
    "                    token.write(creds.to_json())\n",
    "            except OSError as e:\n",
    "                raise GDRiveError(f'error writing token file: {token} - {e}')\n",
    "\n",
    "\n",
    "        return creds    \n",
    "# \n",
    "    \n",
    "    @staticmethod\n",
    "    def build_service(credentials):\n",
    "        try:\n",
    "            service  = build('drive', 'v3', credentials=credentials)\n",
    "        except google_exceptions.GoogleAuthError as e:\n",
    "            raise GDriveError(f'error building credentials: {e}')\n",
    "        return service\n",
    "    \n",
    "                \n",
    "    @property\n",
    "    def token(self):\n",
    "        '''token file'''\n",
    "        return self._token\n",
    "        \n",
    "    @token.setter\n",
    "    def token(self, t_path):\n",
    "        t_path = Path(t_path)        \n",
    "        self._token = t_path\n",
    "        \n",
    "        \n",
    "    def _interface(self, name=None, trashed=False, mimeType=None, fuzzy=True, \n",
    "               modifiedTime=None, parents=None, dopperator='>',\n",
    "               fields = [], forcefields=False,\n",
    "               corpora='user', orderBy='createdTime', driveId='',):\n",
    "        \n",
    "        query_build = {\n",
    "            'name': (name, f'name {\"contains\" if fuzzy else \"=\"} \"{name}\"'),\n",
    "            'trashed': (trashed, f'trashed={trashed}'),\n",
    "            'mimeType': (mimeType, f'mimeType=\"{self.MIMETYPES[mimeType] if mimeType in self.MIMETYPES else \"\"}\"'),\n",
    "            'parents': (parents, f'\"{parents}\" in parents'),\n",
    "            'modifiedTime': (modifiedTime, f'modifiedTime{dopperator}\"{modifiedTime}\"')\n",
    "        }\n",
    "        \n",
    "        query = [v[1] for k, v in query_build.items() if v[0]]\n",
    "        \n",
    "        if len(fields) < 1:\n",
    "            fields = self.FIELDS_DEFAULT\n",
    "        fields = set(fields)\n",
    "        known_fields = []\n",
    "        for f in fields:\n",
    "            if f not in self.FILE_FIELDS:\n",
    "                if forcefields:\n",
    "                    logger.warning(f'unknown return field: {f}')\n",
    "                    known_fields.append(f)\n",
    "                else:\n",
    "                    raise GDriveError(f'unknown return field: {f}')\n",
    "            else:\n",
    "                known_fields.append(f)\n",
    "        fields_string = f'nextPageToken, files({\",\".join(known_fields)})'\n",
    "        \n",
    "        if driveId:\n",
    "            corpora = 'drive'\n",
    "        if corpora not in self.CORPORA:\n",
    "            raise GDriveError(f'unknown `corpora` value: {corpora}')\n",
    "        else:\n",
    "            includeItemsFromAllDrives = self.CORPORA[corpora]['params']['includeItemsFromAllDrives']\n",
    "            supportsAllDrives = self.CORPORA[corpora]['params']['supportsAllDrives']\n",
    "            \n",
    "        q = ' and '.join(query)\n",
    "        logger.debug(f'QUERY STRING: {q}')\n",
    "        \n",
    "        return {'q': q,\n",
    "                'corpora': corpora,\n",
    "                'includeItemsFromAllDrives': includeItemsFromAllDrives,\n",
    "                'supportsAllDrives': supportsAllDrives,\n",
    "                'fields_string': fields_string,\n",
    "                'driveId': driveId,\n",
    "                }\n",
    "    \n",
    "    @credential_wrapper\n",
    "    @sleep_and_retry\n",
    "    @limits(calls=constants_GDrive.CALL_LIMIT, period=constants_GDrive.CALL_PERIOD)\n",
    "    def _list(self, q='', corpora='', includeItemsFromAllDrives=False,\n",
    "             supportsAllDrives='', fields_string='', driveId='', \n",
    "              pageToken='', pageSize=constants_GDrive.PAGESIZE):\n",
    "        logger.debug(f'fettching page of {pageSize} results with query {q}')\n",
    "        try:\n",
    "            results = self.service.files().list(q=q,\n",
    "                                                corpora=corpora,\n",
    "                                                includeItemsFromAllDrives=includeItemsFromAllDrives,\n",
    "                                                supportsAllDrives=supportsAllDrives,\n",
    "                                                fields=fields_string,\n",
    "                                                driveId=driveId,\n",
    "                                                pageSize=pageSize,\n",
    "                                                pageToken=pageToken\n",
    "                                                ).execute()\n",
    "        except HttpError as e:\n",
    "            raise GDriveError(f'error searching: {type(e)}: {e}')\n",
    "\n",
    "        return results\n",
    "\n",
    "        \n",
    "    def search(self, name=None, trashed=False, mimeType=None, fuzzy=True, \n",
    "               modifiedTime=None, parents=None, dopperator='>',\n",
    "               fields = [], forcefields=False,\n",
    "               corpora='user', orderBy='createdTime', driveId='',\n",
    "               pageSize=constants_GDrive.PAGESIZE, complete=True,\n",
    "               pageToken=''):\n",
    "        '''search for objects in google drive by name\n",
    "\n",
    "        Args:\n",
    "            name(str): string to search for\n",
    "            trashed(bool): search in trash when true\n",
    "            mimeType(str): short mimeType (see MIMETYPES property)\n",
    "            fuzzy(bool): true: `name contains \"value\"` false: `name = \"value\"`\n",
    "            modifiedTime(str): yyyy-mm-dd string\n",
    "            dopperator(str): >, < for use with modifiedTime\n",
    "            parents(str): folder to search within\n",
    "            fields(list of str): fields to return (see FILE_FIELDS property)\n",
    "            forcefields(bool): true: use unknown fields, false: reject fields not in FILE_FIELDS\n",
    "            corpora(str): locations to search (see CORPORA property)\n",
    "            orderBy(str): order results by (see https://developers.google.com/drive/api/v3/reference/files/list)\n",
    "            driveId(str): search this shared drive\n",
    "            pageSize(int): number of results to return per page (default 300)\n",
    "            complete(bool): true: exhaust all nextPageTokens\n",
    "\n",
    "        Retruns dict of resutls\n",
    "            '''\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         query_build = {\n",
    "#             'name': (name, f'name {\"contains\" if fuzzy else \"=\"} \"{name}\"'),\n",
    "#             'trashed': (trashed, f'trashed={trashed}'),\n",
    "#             'mimeType': (mimeType, f'mimeType=\"{self.MIMETYPES[mimeType] if mimeType in self.MIMETYPES else \"\"}\"'),\n",
    "#             'parents': (parents, f'\"{parents}\" in parents'),\n",
    "#             'modifiedTime': (modifiedTime, f'modifiedTime{dopperator}\"{modifiedTime}\"')\n",
    "#         }\n",
    "\n",
    "#         query = [v[1] for k, v in query_build.items() if v[0]]\n",
    "\n",
    "#         if len(fields) < 1:\n",
    "#             fields = self.FIELDS_DEFAULT\n",
    "#         fields = set(fields)\n",
    "\n",
    "#         known_fields = []\n",
    "#         for f in fields:\n",
    "#             if f not in self.FILE_FIELDS:\n",
    "#                 if forcefields:\n",
    "#                     logger.warning(f'unknown return field: {f}')\n",
    "#                     known_fields.append(f)\n",
    "#                 else:\n",
    "#                     raise GDriveError(f'unknown return field: {f}')\n",
    "#             else:\n",
    "#                 known_fields.append(f)\n",
    "\n",
    "#         fields_string = f'nextPageToken, files({\",\".join(known_fields)})'\n",
    "\n",
    "\n",
    "#         if driveId:\n",
    "#             corpora = 'drive'\n",
    "\n",
    "#         if corpora not in self.CORPORA:\n",
    "#             raise GDriveError(f'unknown `corpora` value: {corpora}')\n",
    "#         else:\n",
    "#             includeItemsFromAllDrives = self.CORPORA[corpora]['params']['includeItemsFromAllDrives']\n",
    "#             supportsAllDrives = self.CORPORA[corpora]['params']['supportsAllDrives']\n",
    "\n",
    "#         q = ' and '.join(query)\n",
    "#         logger.debug(f'QUERY STRING: {q}')\n",
    "        \n",
    "        \n",
    "    \n",
    "        interface = self._interface(name=name, trashed=trashed, mimeType=mimeType, fuzzy=fuzzy, \n",
    "               modifiedTime=modifiedTime, parents=parents, dopperator=dopperator,\n",
    "               fields = fields, forcefields=forcefields,\n",
    "               corpora=corpora, orderBy=orderBy, driveId=driveId)\n",
    "        \n",
    "        file_list = []\n",
    "        search_result = self._list(pageToken=pageToken, **interface)\n",
    "                    \n",
    "        token = search_result.get('nextPageToken', False)\n",
    "        file_list.extend(search_result.get('files', []))\n",
    "        \n",
    "        while token and complete:\n",
    "            logger.debug(f'processing additional pages of results')\n",
    "            search_result = self._list(pageToken=token, **interface) # need to pass pagetoken=token and **interface\n",
    "            token = search_result.get('nextPageToken', False)\n",
    "            file_list.extend(search_result.get('files', []))\n",
    "\n",
    "\n",
    "        logger.debug(f'{len(file_list)} total matches returned')\n",
    "        \n",
    "\n",
    "\n",
    "        return file_list\n",
    "        \n",
    "    def ls(self, *args, **kwargs):\n",
    "        '''print lis of files in a google drive using any of the search properties'''\n",
    "\n",
    "        result = self.search(*args, **kwargs)\n",
    "        for file in result.get('files', []):\n",
    "            print(('name: {f[name]}, ID:{f[id]}, mimeType:{f[mimeType]}'.format(f=file)))\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def add(self, name, parents=None, fields=['webViewLink, mimeType, id']):\n",
    "        '''add a file to google drive\n",
    "        Args:\n",
    "            name(str): name of file\n",
    "            parents(str): parent folder to place item in\n",
    "            fields(list of str): fields to return after uploading file\n",
    "            \n",
    "        Returns:\n",
    "            list of str upon success\n",
    "        '''\n",
    "        \n",
    "        if not parents:\n",
    "            parents = ''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8e3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ce1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:googleapiclient.discovery_cache:file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "sec = '../secrets/client_secret_910311278281-bh8qk3kmgk0veri3v8en260e76ipafpj.apps.googleusercontent.com.json'\n",
    "d = GDrive(secrets=sec, scopes=constants.SCOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206827d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = d._interface(parents='0B9WTleJ1MzaYT2pieWNXYkZtZm8', trashed=False, fields=['parents', 'id', 'name', 'mimeType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a51338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:QUERY STRING: name contains \"Job Description\"\n",
      "DEBUG:__main__:fettching page of 300 results with query name contains \"Job Description\"\n",
      "DEBUG:__main__:7 total matches returned\n"
     ]
    }
   ],
   "source": [
    "r = d.search(name='Job Description', fields=['parents', 'id', 'name', 'mimeType'], pageSize=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec3f5289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1tu9MiR2744cskSukHFn4zW_axxVw7tIXDzllvguSW_A',\n",
       "  'name': 'IT Security Manager Job Description',\n",
       "  'mimeType': 'application/vnd.google-apps.document',\n",
       "  'parents': ['0B9WTleJ1MzaYMFBvNko3M0RiY0E']},\n",
       " {'id': '1ROfMqpg2p6b44_NvLm-TU7Qdi_6Fuwh-fZyNSSUb_jc',\n",
       "  'name': 'Notes IT Security Job Description',\n",
       "  'mimeType': 'application/vnd.google-apps.document',\n",
       "  'parents': ['0B9WTleJ1MzaYMFBvNko3M0RiY0E']},\n",
       " {'id': '1KtyNP26Zh2P3XifmT7eCevUaV45P-6E4',\n",
       "  'name': 'HS International Baccalaureate Coordinator 2020-2021 Job Description.pdf',\n",
       "  'mimeType': 'application/pdf',\n",
       "  'parents': ['1It1PDdpJXRFBx_7nuHmPflYYFqUmaBW_']},\n",
       " {'id': '0Byt14NjSl0Z7d1R4YXozc3BjdmpzLXMtdXVoU3dnOXkwUGhV',\n",
       "  'name': 'EDEP list job descriptions 19-20.pdf',\n",
       "  'mimeType': 'application/pdf'},\n",
       " {'id': '14-a9vySk4Vpp-Yj1fBGXVHsA2f8nmuUqGLVonvs9Pn8',\n",
       "  'name': 'Proposal - ECC Techology Integrator Job Description 2017/18 ',\n",
       "  'mimeType': 'application/vnd.google-apps.document'},\n",
       " {'id': '0B3JoU6opCIINTWxhM3lNemdvWFE',\n",
       "  'name': '_PE Dept Coord job description - 28 March 2014.doc',\n",
       "  'mimeType': 'application/msword',\n",
       "  'parents': ['0B3JoU6opCIINUHJyeTF1NkxmNm8']},\n",
       " {'id': '0B3JoU6opCIINUHJyeTF1NkxmNm8',\n",
       "  'name': 'Job Descriptions - random',\n",
       "  'mimeType': 'application/vnd.google-apps.folder',\n",
       "  'parents': ['0B3JoU6opCIINZDZiemdMdEREMnM']}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e949a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = d._list(**iface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56759bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r['files'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurse_folders(drive, parents, \n",
    "                    fields=['parents', 'id', 'name', 'mimeType', 'owners', 'modifiedTime', 'webViewLink', 'parents'], \n",
    "                    file_list=[], skipped=[], depth=0):\n",
    "    '''recursively find all files in a google drive folder'''\n",
    "    if depth == 0:\n",
    "        file_list = []\n",
    "        skipped = []\n",
    "    logger.info(f'recursion depth: {depth}')\n",
    "    try:\n",
    "        result = drive.search(parents=parents, fields=fields)\n",
    "    except GDriveError as e:\n",
    "        logger.error(f'error accessing google drive: {e}')\n",
    "        skipped.append(parents)\n",
    "        result = {}\n",
    "        \n",
    "    for f in result:\n",
    "        if drive.MIMETYPES['folder'] == f.get('mimeType'):\n",
    "            return_files, return_skipped = recurse_folders(drive=drive, parents=f['id'], \n",
    "                                         fields=fields, \n",
    "                                         file_list=file_list,\n",
    "                                         skipped=skipped,\n",
    "                                         depth=depth+1)\n",
    "            file_list + return_files\n",
    "            skipped + return_files\n",
    "        else:\n",
    "            file_list.append(f)\n",
    "    return (file_list, skipped)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = recurse_folders(d, \"0B9WTleJ1MzaYMFBvNko3M0RiY0E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566b826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_credentials(secret, token, scopes):\n",
    "#     token = Path(token).expanduser()\n",
    "#     secret = Path(secret).expanduser()\n",
    "#     creds = None\n",
    "    \n",
    "#     if token.exists():\n",
    "#         creds = Credentials.from_authorized_user_file(token, scopes)\n",
    "        \n",
    "    \n",
    "#     if not creds or not creds.valid:\n",
    "#         if creds and creds.expired and creds.refresh_token:\n",
    "#             creds.refresh(Request())    \n",
    "#         else:\n",
    "#             flow = InstalledAppFlow.from_client_secrets_file(secret)\n",
    "#             creds = flow.run_local_server(port=0)\n",
    "#         # Save the credentials for the next run\n",
    "#         try:\n",
    "#             with open('token.json', 'w') as token:\n",
    "#                 token.write(creds.to_json())\n",
    "#         except OSError as e:\n",
    "#             raise GDRiveError(f'error writing token file: {token} - {e}')\n",
    "            \n",
    "    \n",
    "#     return creds\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger.debug('foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DC():\n",
    "    '''dummy class for developing class functions'''\n",
    "    pass\n",
    "self = DC()\n",
    "# self.mimetypes = constants_GDrive.MIMETYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recurseFolders(myDrive, parents=\"\", fieldNames='parents, id, name', fileList=[], skipped=[], depth=0):\n",
    "#     if depth == 0:\n",
    "#         fileList = []\n",
    "#         skipped = []\n",
    "#     logger.info('depth: ', depth)\n",
    "#     try:\n",
    "#         result = myDrive.search(parents=parents, fields=fieldNames)\n",
    "#     except GDriveError as e:\n",
    "#         logger.error(e)\n",
    "#         skipped.append(parents)\n",
    "#     for file in result['files']:\n",
    "#         if file['mimeType'] == 'application/vnd.google-apps.folder':\n",
    "#             returnVals = recurseFolders(myDrive=myDrive, parents=file['id'], fieldNames=fieldNames, fileList=fileList, \n",
    "#                                         skipped=skipped, depth=depth+1)\n",
    "#             fileList + returnVals[0]\n",
    "#             skipped + returnVals[1]\n",
    "#         else:\n",
    "#             fileList.append(file)\n",
    "    \n",
    "#     return(fileList, skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_auth(f):\n",
    "#     def wrapper(*args):\n",
    "#         print('args: ', args)\n",
    "#         print(dir(args))\n",
    "#         return f(*args)\n",
    "#     return wrapper\n",
    "\n",
    "# class GD(object):\n",
    "#     def __init__(self):\n",
    "#         self.authorized = False\n",
    "    \n",
    "#     @check_auth\n",
    "#     def get(self):\n",
    "#         print( 'get')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb366296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import wraps\n",
    "\n",
    "# def wrapper(method):\n",
    "#     @wraps(method)\n",
    "#     def _impl(self, *method_args, **method_kwargs):\n",
    "#         if self.auth == False:\n",
    "#             print('wrapper: not authorized!')\n",
    "#             self.auth = 77\n",
    "#         method_output = method(self, *method_args, **method_kwargs)\n",
    "#         return method_output\n",
    "#     return _impl\n",
    "\n",
    "# class Foo:\n",
    "#     def __init__(self):\n",
    "#         self.auth = False\n",
    "#         self.list = []\n",
    "        \n",
    "#     @wrapper\n",
    "#     def bar(self, word):\n",
    "#         self.list.append(word)\n",
    "#         return self.list\n",
    "\n",
    "# f = Foo()\n",
    "# f.bar(\"kitty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foof(a, **kwargs):\n",
    "    print(a)\n",
    "foof(**{'a': 'snek','b': 'trash panda'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e45db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.root.setLevel('INFO')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel('DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ebb423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:foo\n"
     ]
    }
   ],
   "source": [
    "logger.debug('foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6278c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter-nbconvert --to python --template python_clean GDrive.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdrive_audit-k7Dny7ri",
   "language": "python",
   "name": "gdrive_audit-k7dny7ri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
